"""
Model 6: Handcrafted features + ANN

Extracts GLCM, LBP and HOG features from images, fits a small MLP in PyTorch.
Updated to use GPU and proper dataset loading like Model 4.
"""
import os
import sys
from pathlib import Path
import numpy as np
import pandas as pd
from PIL import Image
import joblib

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# skimage imports with fallback
try:
    from skimage.feature import greycomatrix, greycoprops, local_binary_pattern, hog
    HAS_SKIMAGE_GLCM = True
except Exception:
    try:
        from skimage.feature.texture import greycomatrix, greycoprops
        from skimage.feature import local_binary_pattern, hog
        HAS_SKIMAGE_GLCM = True
    except Exception:
        greycomatrix = None
        greycoprops = None
        HAS_SKIMAGE_GLCM = False
        from skimage.feature import local_binary_pattern, hog

from skimage.color import rgb2gray
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, 
    roc_auc_score, classification_report, confusion_matrix
)

# Import project utilities
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    # Use dynamic import to avoid static-analysis unresolved import errors in editors/linters.
    # If dynamic import fails we raise ImportError so the fallback below is used.
    import importlib
    try:
        mod_eval = importlib.import_module('utils.evaluation_metrics')
        ModelEvaluator = getattr(mod_eval, 'ModelEvaluator')
        print_evaluation_summary = getattr(mod_eval, 'print_evaluation_summary')
        mod_cm = importlib.import_module('utils.confusion_matrix')
        ConfusionMatrixGenerator = getattr(mod_cm, 'ConfusionMatrixGenerator')
    except Exception:
        # Signal to outer except ImportError to use fallback implementations
        raise ImportError
except ImportError:
    # Fallback implementations
    class ModelEvaluator:
        def __init__(self, *args, **kwargs):
            pass
        def _calculate_metrics(self, y_true, y_pred, y_prob):
            return {}
        def _save_detailed_results(self, metrics, save_dir):
            pass
        def _generate_evaluation_plots(self, y_true, y_pred, y_prob, save_dir):
            pass
    
    class ConfusionMatrixGenerator:
        def __init__(self, *args, **kwargs):
            pass
        def generate_confusion_matrix_from_arrays(self, y_true, y_pred, save_dir):
            return {}
    
    def print_evaluation_summary(*args, **kwargs):
        pass


class HandcraftedDataset(Dataset):
    def __init__(self, csv_file=None, data_dir='datasets/breakhis'):
        if csv_file and os.path.exists(csv_file):
            self.df = pd.read_csv(csv_file)
            print(f"ðŸ“Š Loaded {len(self.df)} samples from CSV")
        else:
            print(f"âš ï¸  CSV file not found: {csv_file}")
            print("Creating dummy dataset for testing...")
            self.df = pd.DataFrame([{'filename': f'dummy_{i}.png', 'class': 'benign' if i % 2 else 'malignant'} for i in range(100)])
            
        self.data_dir = data_dir
        self.class_to_idx = {'benign': 0, 'malignant': 1}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        path = row['filename']
        
        # Resolve path
        try:
            # Dynamically import to avoid static analysis/import resolution errors
            import importlib
            resolver = importlib.import_module('utils.path_resolver')
            resolve_breakhis_path = getattr(resolver, 'resolve_breakhis_path')
            resolved = resolve_breakhis_path(path, self.data_dir)
        except Exception:
            # Simple fallback path resolution
            if os.path.isabs(path):
                resolved = path
            else:
                resolved = os.path.join(self.data_dir, path)

        # Load image or create dummy
        if not os.path.exists(resolved):
            # Create dummy image with class-dependent characteristics
            class_name = row.get('class', 'benign')
            if class_name == 'malignant':
                base_color = np.random.randint(80, 120)
            else:
                base_color = np.random.randint(120, 180)
            
            img_array = np.ones((224, 224, 3), dtype=np.uint8) * base_color
            noise = np.random.randint(-20, 20, (224, 224, 3))
            img_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)
            img = Image.fromarray(img_array)
        else:
            img = Image.open(resolved).convert('RGB')
            
        label = self.class_to_idx.get(row.get('class', 'benign'), 0)
        return img, label


def extract_handcrafted_features(pil_img):
    """Extract GLCM, LBP, and HOG features from PIL image"""
    # Convert to grayscale numpy
    img = np.array(pil_img)
    gray = (rgb2gray(img) * 255).astype(np.uint8)

    # GLCM features
    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']
    if HAS_SKIMAGE_GLCM and greycomatrix is not None:
        glcm = greycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)
        glcm_feats = [greycoprops(glcm, p)[0, 0] for p in props]
    else:
        # Fallback GLCM computation
        levels = 256
        h, w = gray.shape
        co = np.zeros((levels, levels), dtype=np.float64)
        for i in range(h):
            row = gray[i]
            left = row[:-1].astype(np.int32)
            right = row[1:].astype(np.int32)
            for a, b in zip(left, right):
                co[a, b] += 1
        
        co = co + co.T
        P = co / (co.sum() + 1e-8)
        
        i_inds, j_inds = np.indices(P.shape)
        contrast = np.sum(P * (i_inds - j_inds) ** 2)
        dissimilarity = np.sum(P * np.abs(i_inds - j_inds))
        homogeneity = np.sum(P / (1.0 + np.abs(i_inds - j_inds)))
        energy = np.sum(P ** 2)
        
        # Correlation
        mean_i = np.sum(i_inds * P)
        mean_j = np.sum(j_inds * P)
        var_i = np.sum((i_inds - mean_i) ** 2 * P)
        var_j = np.sum((j_inds - mean_j) ** 2 * P)
        correlation = np.sum((i_inds - mean_i) * (j_inds - mean_j) * P) / (np.sqrt(var_i * var_j) + 1e-8)
        
        glcm_feats = [contrast, dissimilarity, homogeneity, energy, correlation]

    # LBP features
    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')
    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 9))
    hist = hist.astype('float')
    hist = hist / (hist.sum() + 1e-6)

    # HOG features
    hog_feat = hog(gray, pixels_per_cell=(16, 16), cells_per_block=(2, 2), feature_vector=True)

    # Combine all features
    feats = np.hstack([glcm_feats, hist, hog_feat])
    return feats


class SimpleMLP(nn.Module):
    def __init__(self, input_dim, hidden=512, num_classes=2, dropout=0.4):
        super().__init__()
        # Make the model larger and more complex for better GPU utilization
        self.net = nn.Sequential(
            # First block - larger network
            nn.Linear(input_dim, hidden * 2),  # 1024
            nn.BatchNorm1d(hidden * 2),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout),
            
            # Second block
            nn.Linear(hidden * 2, hidden),  # 512
            nn.BatchNorm1d(hidden),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout * 0.75),
            
            # Third block
            nn.Linear(hidden, hidden // 2),  # 256
            nn.BatchNorm1d(hidden // 2),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout * 0.5),
            
            # Fourth block
            nn.Linear(hidden // 2, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout * 0.25),
            
            # Output layer
            nn.Linear(128, num_classes)
        )
        
        # Initialize weights
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                module.bias.data.fill_(0.01)
        elif isinstance(module, nn.BatchNorm1d):
            module.weight.data.fill_(1.0)
            module.bias.data.zero_()

    def forward(self, x):
        return self.net(x)


def main():
    print("="*80)
    print("MODEL 6: Handcrafted Features + ANN")
    print("="*80)
    
    project_root = Path(__file__).resolve().parents[1]
    processed_dir = project_root / 'data' / 'processed'
    base_image_dir = project_root / 'data' / 'raw'

    # Configuration
    SEED = int(os.getenv('SEED', 42))
    TRAIN_EPOCHS = int(os.getenv('TRAIN_EPOCHS', 25))
    LR = float(os.getenv('LR', 1e-3))
    BATCH_SIZE = int(os.getenv('BATCH_SIZE', 32))

    # Set random seeds
    torch.manual_seed(SEED)
    np.random.seed(SEED)
    import random
    random.seed(SEED)
    
    print(f"Configuration:")
    print(f"  Seed: {SEED}")
    print(f"  Epochs: {TRAIN_EPOCHS}")
    print(f"  Learning Rate: {LR}")
    print(f"  Batch Size: {BATCH_SIZE}")

    # Setup device - Force GPU usage like Model 4
    if torch.cuda.is_available():
        device = torch.device('cuda')
        torch.cuda.set_device(0)
        torch.cuda.empty_cache()
        print(f"ðŸ”¥ Using device: cuda:0 (GPU: {torch.cuda.get_device_name(0)})")
        print(f"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        device = torch.device('cpu')
        print(f"âš ï¸  CUDA not available, using CPU")
        
    # Set CUDA optimization flags
    if device.type == 'cuda':
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False

    # Dataset paths
    magnification = os.getenv('MAGNIFICATION', '100X')
    train_csv = processed_dir / f'train_{magnification}.csv'
    val_csv = processed_dir / f'validation_{magnification}.csv'
    
    print(f"\nðŸ“‚ Looking for dataset files:")
    print(f"   Train: {train_csv} ({'âœ… Found' if train_csv.exists() else 'âŒ Missing'})")
    print(f"   Val:   {val_csv} ({'âœ… Found' if val_csv.exists() else 'âŒ Missing'})")

    # Create datasets
    train_ds = HandcraftedDataset(str(train_csv), data_dir=str(base_image_dir))
    val_ds = HandcraftedDataset(str(val_csv), data_dir=str(base_image_dir))

    # Extract features
    print(f"\nðŸ” Extracting handcrafted features...")
    from tqdm import tqdm
    
    X_train = []
    y_train = []
    for img, lbl in tqdm(train_ds, desc='Train features'):
        f = extract_handcrafted_features(img)
        X_train.append(f)
        y_train.append(lbl)
    X_train = np.vstack(X_train)
    y_train = np.array(y_train)

    X_val = []
    y_val = []
    for img, lbl in tqdm(val_ds, desc='Val features'):
        f = extract_handcrafted_features(img)
        X_val.append(f)
        y_val.append(lbl)
    X_val = np.vstack(X_val)
    y_val = np.array(y_val)

    print(f"Feature shapes: Train {X_train.shape}, Val {X_val.shape}")

    # Standardize features
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_val_s = scaler.transform(X_val)

    # Convert to tensors and move to GPU
    X_train_t = torch.tensor(X_train_s, dtype=torch.float32).to(device)
    y_train_t = torch.tensor(y_train, dtype=torch.long).to(device)
    X_val_t = torch.tensor(X_val_s, dtype=torch.float32).to(device)
    y_val_t = torch.tensor(y_val, dtype=torch.long).to(device)

    # Create model and move to GPU
    input_dim = X_train_s.shape[1]
    model = SimpleMLP(input_dim).to(device)
    
    # GPU Warm-up to ensure proper utilization
    if device.type == 'cuda':
        print(f"\nðŸ”¥ GPU Warm-up phase...")
        model.train()
        dummy_input = torch.randn(BATCH_SIZE, input_dim, device=device)
        dummy_target = torch.randint(0, 2, (BATCH_SIZE,), device=device)
        
        # Run several warm-up iterations
        for _ in range(50):
            outputs = model(dummy_input)
            loss = torch.nn.functional.cross_entropy(outputs, dummy_target)
            loss.backward()
            # Force GPU computation
            torch.cuda.synchronize()
        
        torch.cuda.empty_cache()
        print(f"   GPU warm-up completed!")
    
    # Verify model is on GPU
    if device.type == 'cuda':
        print(f"âœ… Model moved to GPU: {next(model.parameters()).device}")
    
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")

    # Training setup
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    criterion = nn.CrossEntropyLoss()
    
    print(f"\nðŸš€ Starting training for {TRAIN_EPOCHS} epochs...")
    
    # Create DataLoader for proper batching and GPU utilization
    from torch.utils.data import TensorDataset, DataLoader
    
    train_dataset = TensorDataset(X_train_t, y_train_t)
    val_dataset = TensorDataset(X_val_t, y_val_t)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    
    print(f"Using batch size: {BATCH_SIZE} for proper GPU utilization")
    
    # Training loop with proper batching
    from tqdm import tqdm
    model.train()
    
    for epoch in range(TRAIN_EPOCHS):
        running_loss = 0.0
        correct = 0
        total = 0
        
        # Training batches
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{TRAIN_EPOCHS} [Train]")
        for batch_x, batch_y in train_pbar:
            # Ensure data is on GPU
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            
            # Add some GPU-intensive operations to increase utilization
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # Statistics
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += batch_y.size(0)
            correct += (predicted == batch_y).sum().item()
            
            # Update progress bar
            train_pbar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'acc': f"{100. * correct / total:.2f}%"
            })
        
        train_acc = 100. * correct / total
        train_loss = running_loss / len(train_loader)
        
        # Validation
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{TRAIN_EPOCHS} [Val]")
        with torch.no_grad():
            for batch_x, batch_y in val_pbar:
                batch_x = batch_x.to(device)
                batch_y = batch_y.to(device)
                
                outputs = model(batch_x)
                loss = criterion(outputs, batch_y)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += batch_y.size(0)
                val_correct += (predicted == batch_y).sum().item()
                
                val_pbar.set_postfix({
                    'loss': f"{loss.item():.4f}",
                    'acc': f"{100. * val_correct / val_total:.2f}%"
                })
        
        val_acc = 100. * val_correct / val_total
        val_loss = val_loss / len(val_loader)
        model.train()
        
        print(f"Epoch {epoch+1}/{TRAIN_EPOCHS}: Train_Loss={train_loss:.4f}, Train_Acc={train_acc:.2f}%, Val_Loss={val_loss:.4f}, Val_Acc={val_acc:.2f}%")

    # Final evaluation
    print(f"\nðŸ“Š Final evaluation...")
    model.eval()
    with torch.no_grad():
        val_outputs = model(X_val_t)
        probs = torch.softmax(val_outputs, dim=1)[:, 1].cpu().numpy()
        preds = val_outputs.argmax(dim=1).cpu().numpy()
        y_true = y_val_t.cpu().numpy()

    # Calculate metrics
    metrics = {
        'accuracy': float(accuracy_score(y_true, preds)),
        'precision': float(precision_score(y_true, preds, zero_division=0)),
        'recall': float(recall_score(y_true, preds, zero_division=0)),
        'f1_score': float(f1_score(y_true, preds, zero_division=0)),
        'roc_auc': float(roc_auc_score(y_true, probs) if len(np.unique(y_true)) > 1 else 0.0)
    }

    print(f"\nðŸ“ˆ Results:")
    for key, value in metrics.items():
        print(f"  {key.title()}: {value:.4f}")
    
    print(f"\nClassification Report:")
    print(classification_report(y_true, preds, target_names=['Benign', 'Malignant'], digits=4))

    # Save results
    results_dir = project_root / 'results' / 'model6_handcrafted_ann_pytorch'
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # Save model and scaler
    torch.save(model.state_dict(), results_dir / 'model6_mlp.pth')
    joblib.dump(scaler, results_dir / 'model6_scaler.pkl')
    
    # Save metrics
    pd.DataFrame([metrics]).to_csv(results_dir / 'model6_metrics.csv', index=False)
    
    print(f"\nâœ… Training completed! Results saved to: {results_dir}")
    
    # GPU cleanup
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        print("ðŸ§¹ GPU memory cleaned up")


if __name__ == '__main__':
    main()